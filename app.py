import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from streamlit_gsheets import GSheetsConnection
import pandas as pd
import yfinance as yf
import re
import json
from datetime import datetime
import time

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="AI é£†è‚¡åµæ¸¬èˆ‡é€±å ±è³‡æ–™åº«", layout="wide", page_icon="ğŸ“ˆ")

try:
    genai.configure(api_key=st.secrets["GEMINI_KEY"])
    # æ¡ç”¨æœ€æ–°çš„ Gemini æ¨¡å‹
    model = genai.GenerativeModel('gemini-2.0-flash') 
    conn = st.connection("gsheets", type=GSheetsConnection)
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Secrets è¨­å®š: {e}")
    st.stop()

# --- 2. æ ¸å¿ƒé‚è¼¯å‡½å¼ ---

def extract_stock_ids(text):
    """å¾æ–‡å­—ä¸­æå– 4 ä½æ•¸å°è‚¡ä»£ç¢¼ï¼Œä¸¦è‡ªå‹•è™•ç†éå­—ä¸²è³‡æ–™"""
    if not isinstance(text, str):
        text = str(text) if text is not None else ""
    return re.findall(r'\b\d{4}\b', text)
def get_stock_perf(sid):
    """ç²å–å°è‚¡å³æ™‚è¡Œæƒ…èˆ‡æ¼²è·Œå¹…"""
    try:
        suffix = ".TW" if int(sid) < 9000 else ".TWO"
        t = yf.Ticker(f"{sid}{suffix}")
        h = t.history(period="1mo")
        if h.empty: return None
        cur = h['Close'].iloc[-1]
        chg = ((cur - h['Close'].iloc[0]) / h['Close'].iloc[0]) * 100
        return {"price": cur, "change": chg}
    except: return None

def check_breakout_dna(sid):
    """
    é£†è‚¡èµ·æ¼² DNA åµæ¸¬ï¼š
    1. å‡ç·šç³¾çµåº¦ < 3.5% (5/10/20 MA)
    2. æˆäº¤é‡èç¸® < 0.75 (ç›¸è¼ƒæ–¼ 20 æ—¥å‡é‡)
    3. è‚¡åƒ¹åœ¨ 60MA (å­£ç·š) ä¹‹ä¸Š (å¤šé ­æ¶æ§‹)
    """
    try:
        suffix = ".TW" if int(sid) < 9000 else ".TWO"
        t = yf.Ticker(f"{sid}{suffix}")
        df = t.history(period="65d") 
        if len(df) < 60: return None
        
        # è¨ˆç®—æŒ‡æ¨™
        df['MA5'] = df['Close'].rolling(5).mean()
        df['MA10'] = df['Close'].rolling(10).mean()
        df['MA20'] = df['Close'].rolling(20).mean()
        df['MA60'] = df['Close'].rolling(60).mean()
        
        last = df.iloc[-1]
        vol_avg20 = df['Volume'].rolling(20).mean().iloc[-1]
        
        # 1. å‡ç·šç³¾çµåº¦
        ma_list = [last['MA5'], last['MA10'], last['MA20']]
        ma_gap = (max(ma_list) / min(ma_list) - 1) * 100
        
        # 2. é‡æ¯”
        v_ratio = last['Volume'] / vol_avg20 if vol_avg20 > 0 else 1
        
        # 3. åˆ¤å®šæ¢ä»¶
        is_ready = (ma_gap < 3.5) and (v_ratio < 0.75) and (last['Close'] > last['MA60'])
        
        return {
            "sid": sid,
            "price": round(last['Close'], 2),
            "gap": round(ma_gap, 2),
            "v_ratio": round(v_ratio, 2),
            "is_ready": is_ready
        }
    except:
        return None

# --- 3. App ä»‹é¢ä½ˆå±€ ---
st.title("ğŸ“‚ å°ˆæ¥­é€±å ± JSON çµæ§‹åŒ–èˆ‡é£†è‚¡ DNA åµæ¸¬ç³»çµ±")
tab1, tab2, tab3, tab4 = st.tabs(["ğŸš€ é€±å ±è§£æ", "ğŸ“… æ­·å²è¨ºæ–·", "ğŸ“š è³‡æ–™åº«æ˜ç´°", "âš¡ é£†è‚¡åµæ¸¬å™¨"])

# é å…ˆè®€å–è³‡æ–™åº«
try:
    db = conn.read(worksheet="Sheet1")
except:
    db = pd.DataFrame()

# --- Tab 1: é€±å ±è§£æ ---
with tab1:
    up_col1, up_col2 = st.columns([3, 1])
    with up_col1:
        uploaded_file = st.file_uploader("ä¸Šå‚³é€±å ± PDF", type="pdf")
    with up_col2:
        re_analyze = st.button("ğŸ”„ é‡æ–°åˆ†æ")

    if uploaded_file:
        if 'json_analysis' not in st.session_state or re_analyze:
            with st.spinner('Gemini æ­£åœ¨é€²è¡Œæ·±åº¦çµæ§‹åŒ–æƒæ...'):
                reader = PdfReader(uploaded_file)
                text = "".join([p.extract_text() for p in reader.pages if p.extract_text()])
                
                prompt = f"""
                ä½ æ˜¯ä¸€ä½å°ˆæ¥­è‚¡ç¥¨åˆ†æå“¡ã€‚è«‹æ·±å…¥åˆ†æé€±å ±å…§å®¹ã€‚
                è«‹è¼¸å‡ºä¸€å€‹ JSON æ ¼å¼åˆ—è¡¨ï¼Œä¸åŒ…å« Markdown æ¨™ç±¤æˆ–é¡å¤–æ–‡å­—ã€‚
                æ ¼å¼ï¼š[{{"é¡Œæ": "åç¨±", "åŸå› ": "10å­—å…§", "æ¨™çš„": "4ä½æ•¸ä»£ç¢¼+åç¨±"}}]
                é€±å ±å…§å®¹ï¼š{text[:15000]}
                """
                res = model.generate_content(prompt)
                st.session_state.json_analysis = res.text
                
                date_match = re.search(r'\d{4}-\d{2}-\d{2}', uploaded_file.name)
                st.session_state.rep_date = date_match.group(0) if date_match else datetime.now().strftime("%Y-%m-%d")

        if 'json_analysis' in st.session_state:
            st.markdown(f"### ğŸ“‹ {st.session_state.rep_date} çµæ§‹åŒ–çµæœ")
            st.code(st.session_state.json_analysis, language='json')

            if st.button("ğŸ“¥ ç¢ºèªå­˜å…¥ Google Sheets"):
                try:
                    raw_str = st.session_state.json_analysis.replace('```json', '').replace('```', '').strip()
                    data_list = json.loads(raw_str)
                    new_df = pd.DataFrame(data_list)
                    new_df['æ—¥æœŸ'] = st.session_state.rep_date
                    final_df = pd.concat([db, new_df[['æ—¥æœŸ', 'é¡Œæ', 'åŸå› ', 'æ¨™çš„']]], ignore_index=True)
                    conn.update(worksheet="Sheet1", data=final_df)
                    st.success("âœ… æ•¸æ“šå·²æˆåŠŸåŒæ­¥è‡³é›²ç«¯è³‡æ–™åº«ï¼")
                except Exception as e:
                    st.error(f"å­˜å…¥å¤±æ•—: {e}")

# --- Tab 2: æ­·å²å›æº¯ ---
with tab2:
    st.subheader("ğŸ“Š æ­·å²æ¨™é¡Œå‹•èƒ½æ¯”å°")
    if not db.empty:
        dates = db['æ—¥æœŸ'].unique()[::-1]
        sel_date = st.selectbox("é¸æ“‡å›æº¯æ—¥æœŸ", dates)
        sub_df = db[db['æ—¥æœŸ'] == sel_date]
        
        for _, row in sub_df.iterrows():
            with st.expander(f"ğŸ“Œ {row['é¡Œæ']} - {row['æ¨™çš„']}"):
                sids = extract_stock_ids(row['æ¨™çš„'])
                for sid in sids:
                    perf = get_stock_perf(sid)
                    if perf:
                        c1, c2 = st.columns(2)
                        c1.metric(f"{sid} ç¾åƒ¹", f"{perf['price']:.2f}")
                        c2.metric("è¿‘ä¸€æœˆå¹…åº¦", f"{perf['change']:.2f}%")
    else:
        st.info("è³‡æ–™åº«å°šç„¡è³‡æ–™ã€‚")

# --- Tab 3: è³‡æ–™åº«æ˜ç´° ---
with tab3:
    st.subheader("ğŸ“š é›²ç«¯è³‡æ–™åº«æ¸…å–®")
    # ä¿®æ­£ï¼š2026 Streamlit è¦ç¯„ï¼Œä½¿ç”¨ width="stretch" å¡«æ»¿å¯¬åº¦
    if not db.empty:
        st.dataframe(db, width="stretch")
    else:
        st.info("ç›®å‰è³‡æ–™åº«å…§æ²’æœ‰æ•¸æ“šã€‚")

# --- Tab 4: âš¡ é£†è‚¡åµæ¸¬å™¨ ---
with tab4:
    st.subheader("âš¡ å°‹æ‰¾èµ·æ¼²é»ï¼šå‡ç·šç³¾çµ + çª’æ¯é‡æƒæ")
    
    # 
    
    mode = st.radio("æƒææ¨¡å¼", ["å¾è³‡æ–™åº«æ¨™çš„æ‰¾æ©Ÿæœƒ", "å…¨å°è‚¡/è‡ªå®šç¾©ç¯„åœæƒæ"], horizontal=True)
    
    search_list = []
    if mode == "å¾è³‡æ–™åº«æ¨™çš„æ‰¾æ©Ÿæœƒ":
        if not db.empty:
            all_sids = []
            # ä¿®æ­£ï¼šåŠ å…¥ str() è½‰æ›èˆ‡ pd.notna åˆ¤æ–·ï¼Œé˜²æ­¢ float éŒ¯èª¤
            for s in db['æ¨™çš„']: 
                clean_s = str(s) if pd.notna(s) else ""
                all_sids.extend(extract_stock_ids(clean_s))
            search_list = list(set(all_sids))
            st.write(f"ğŸ” ç›®å‰ç›£æ§è³‡æ–™åº«ä¸­ {len(search_list)} æª”æ¨™çš„...")
        else:
            st.warning("è³‡æ–™åº«æ˜¯ç©ºçš„ï¼Œè«‹å…ˆè§£æé€±å ±ã€‚")
    else:
        raw_input = st.text_area("è¼¸å…¥è‡ªå®šç¾©ä»£ç¢¼ (é€—è™Ÿåˆ†éš”)", "6187, 3363, 3450, 2338, 4977, 8183, 2493, 3017")
        search_list = [s.strip() for s in raw_input.split(",") if s.strip()]

    if st.button("ğŸš€ é–‹å§‹ DNA æƒæ"):
        if search_list:
            results = []
            bar = st.progress(0)
            status_text = st.empty()
            
            for i, sid in enumerate(search_list):
                status_text.text(f"æ­£åœ¨åˆ†æ {sid}...")
                res = check_breakout_dna(sid)
                if res and res['is_ready']:
                    results.append(res)
                bar.progress((i + 1) / len(search_list))
            
            status_text.empty()
            if results:
                st.success(f"ğŸŠ ç™¼ç¾ {len(results)} æª”ç¬¦åˆèµ·æ¼²ç‰¹å¾µï¼")
                res_df = pd.DataFrame(results).drop(columns=['is_ready'])
                res_df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'ç›®å‰åƒ¹æ ¼', 'å‡ç·šç³¾çµåº¦(%)', 'æˆäº¤é‡æ¯”']
                # é€™è£¡ä¹ŸåŒæ­¥ä¿®æ­£å¯¬åº¦è¨­å®š
                st.dataframe(res_df, width="stretch")
            else:
                st.info("ç›®å‰é¸å®šç¯„åœå…§ï¼Œå°šç„¡æ¨™çš„åŒæ™‚æ»¿è¶³ã€Œå‡ç·šç³¾çµã€èˆ‡ã€Œç¸®é‡ã€æ¢ä»¶ã€‚")
            else:
                st.info("ç›®å‰é¸å®šç¯„åœå…§ï¼Œå°šç„¡æ¨™çš„åŒæ™‚æ»¿è¶³ã€Œå‡ç·šç³¾çµã€èˆ‡ã€Œç¸®é‡ã€æ¢ä»¶ã€‚")
