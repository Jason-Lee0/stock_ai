import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from streamlit_gsheets import GSheetsConnection
import pandas as pd
import yfinance as yf
import twstock
import re
import json
import time
import datetime
import concurrent.futures
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# --- 1. ç³»çµ±åˆå§‹åŒ– ---
st.set_page_config(page_title="AI é£†è‚¡è¨ºæ–· v4.8", layout="wide", page_icon="ğŸ›¡ï¸")

# åˆå§‹åŒ– Session State (é˜²æ­¢ Rerun å°è‡´æ•¸æ“šæ¶ˆå¤±)
keys = ['v48_results', 'raw_json', 'rep_date', 'backtest_df']
for key in keys:
    if key not in st.session_state:
        st.session_state[key] = None

try:
    genai.configure(api_key=st.secrets["GEMINI_KEY"])
    model = genai.GenerativeModel('gemini-2.0-flash') 
    conn = st.connection("gsheets", type=GSheetsConnection)
except Exception as e:
    st.error(f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ secrets è¨­å®š: {e}")
    st.stop()

# --- 2. æ ¸å¿ƒé‹ç®—å‡½å¼ ---

def get_taiwan_stock_tickers():
    """ç²å–ç²¾ç¢ºå°è‚¡æ¸…å–® (éæ¿¾æ¬Šè­‰èˆ‡ ETF)"""
    all_codes = twstock.codes
    taiwan_tickers = []
    for code, info in all_codes.items():
        if not code.isdigit() or len(code) != 4: continue
        if "æ¬Šè­‰" in info.type or "ETF" in info.type: continue
        suffix = ".TW" if info.market == "ä¸Šå¸‚" else ".TWO"
        taiwan_tickers.append(f"{code}{suffix}")
    return list(set(taiwan_tickers))

def get_historical_theme_ai(ticker, name):
    """AI è€ƒå¤å­¸ï¼šå›æº¯è©²è‚¡éå»åŠå¹´æ¼²å¹…æœ€å¤§æ™‚çš„å¸‚å ´åˆ©å¤šåŸå› """
    try:
        df = yf.Ticker(ticker).history(period="6mo")
        if df.empty: return "ç„¡è¶³å¤ æ­·å²æ•¸æ“š"
        df['Pct'] = df['Close'].pct_change()
        max_day = df['Pct'].idxmax()
        date_str = max_day.strftime('%Y-%m-%d')
        
        prompt = f"åˆ†æå°è‚¡ {name}({ticker})ã€‚è©²è‚¡åœ¨ {date_str} å‰å¾Œæ›¾å¤§å¹…ä¸Šæ¼²ã€‚è«‹ç°¡çŸ­èªªæ˜ç•¶æ™‚è©²è‚¡çˆ†ç™¼çš„ä¸»å› ï¼ˆå¦‚ï¼šç‡Ÿæ”¶ã€ç‰¹å®šé¡Œææˆ–ç”¢æ¥­èƒŒæ™¯ï¼‰ï¼Œé™ 40 å­—å…§ã€‚"
        response = model.generate_content(prompt)
        return f"ğŸ“… {date_str} çˆ†ç™¼ä¸»å› ï¼š{response.text}"
    except: return "æš«æ™‚ç„¡æ³•è€ƒå¤è©²è‚¡æ­·å²ã€‚"

def check_breakout_v48(ticker, g_limit, v_limit, min_v, bias_limit):
    """æ·±åº¦ç¯©é¸ï¼šæ•´åˆç³¾çµåº¦ã€çª’æ¯é‡ã€å¹´ç·šä¹–é›¢ç‡"""
    today = datetime.date.today()
    # é€±æœ«è‡ªå‹•é–å®šé€±äº”æ•¸æ“š
    end_date = today - datetime.timedelta(days=today.weekday() - 4) if today.weekday() >= 5 else today
    start_date = end_date - datetime.timedelta(days=400)
    
    try:
        df = yf.Ticker(ticker).history(start=start_date, end=end_date)
        if df.empty or len(df) < 245: return None
        last = df.iloc[-1]
        
        # 1. æµå‹•æ€§éæ¿¾ (å¼µæ•¸)
        if (last['Volume'] / 1000) < min_v: return None
        
        # 2. è¨ˆç®—å‡ç·š
        ma_s = df['Close'].rolling(5).mean().iloc[-1]
        ma_m = df['Close'].rolling(10).mean().iloc[-1]
        ma_l = df['Close'].rolling(20).mean().iloc[-1]
        ma60 = df['Close'].rolling(60).mean().iloc[-1]
        ma240 = df['Close'].rolling(240).mean().iloc[-1]
        
        # 3. ä¹–é›¢ç‡éæ¿¾ (é›¢å¹´ç·šå¤ªé ä¸è²·)
        bias_240 = round(((last['Close'] / ma240) - 1) * 100, 2)
        if bias_240 > bias_limit: return None 
        
        # 4. å‡ç·šç³¾çµåº¦ (5, 10, 20MA)
        ma_list = [ma_s, ma_m, ma_l]
        gap = round((max(ma_list) / min(ma_list) - 1) * 100, 2)
        
        # 5. æˆäº¤é‡æ¯” (çª’æ¯é‡åµæ¸¬)
        vol_avg20 = df['Volume'].rolling(20).mean().iloc[-1]
        v_ratio = round(last['Volume'] / vol_avg20, 2)
        
        # 6. å‹•èƒ½åˆ¤å®š (MACD æŸ±ç‹€é«”)
        exp1 = df['Close'].ewm(span=12, adjust=False).mean()
        exp2 = df['Close'].ewm(span=26, adjust=False).mean()
        macd_h = (exp1 - exp2) - (exp1 - exp2).ewm(span=9, adjust=False).mean()
        
        # æ¢ä»¶ï¼šç³¾çµ + é‡ç¸® + åƒ¹æ ¼åœ¨å­£ç·š(60MA)ä¹‹ä¸Šä¸”å­£ç·šä¸Šæš
        if gap <= g_limit and v_ratio <= v_limit and last['Close'] > ma60:
            pure_sid = re.search(r'\d{4}', ticker).group(0)
            info = twstock.codes.get(pure_sid)
            return {
                "ä»£è™Ÿ": ticker, "åç¨±": info.name if info else "æœªçŸ¥",
                "é¡è‚¡": info.category if info else "å…¶ä»–",
                "ç¾åƒ¹": round(last['Close'], 2), "ç³¾çµ(%)": gap, "é‡æ¯”": v_ratio,
                "å¹´ç·šä¹–é›¢(%)": bias_240,
                "å‹•èƒ½": "ğŸ”¥ è½‰å¼·" if macd_h.iloc[-1] > macd_h.iloc[-2] else "â³ æ•´ç†"
            }
    except: return None

# --- 3. ç¹ªåœ–èˆ‡äº’å‹•çµ„ä»¶ ---

def plot_v48(ticker):
    try:
        df = yf.Ticker(ticker).history(period="300d")
        for p in [5, 20, 60, 240]: df[f'MA{p}'] = df['Close'].rolling(p).mean()
        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_heights=[0.7, 0.3])
        fig.add_trace(go.Candlestick(x=df.index, open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'], name="Kç·š"), row=1, col=1)
        for ma, col in zip(['MA5','MA20','MA60','MA240'], ['white','yellow','orange','purple']):
            fig.add_trace(go.Scatter(x=df.index, y=df[ma], name=ma, line=dict(color=col, width=1.5)), row=1, col=1)
        v_cols = ['red' if df['Close'].iloc[i] >= df['Open'].iloc[i] else 'green' for i in range(len(df))]
        fig.add_trace(go.Bar(x=df.index, y=df['Volume'], name="æˆäº¤é‡", marker_color=v_cols), row=2, col=1)
        fig.update_layout(template="plotly_dark", height=500, xaxis_rangeslider_visible=False, margin=dict(l=5, r=5, t=10, b=5))
        return fig
    except: return None

@st.dialog("ğŸš€ AI é£†è‚¡æ·±åº¦è¨ºæ–·å®¤", width="large")
def show_stock_v48(ticker, name):
    st.write(f"### {name} ({ticker})")
    with st.spinner("AI æ­£åœ¨è€ƒå¤è©²è‚¡åŸºå› ..."):
        story = get_historical_theme_ai(ticker, name)
        st.info(story)
    chart = plot_v48(ticker)
    if chart: st.plotly_chart(chart, width='stretch', use_container_width=True)
    if st.button("é—œé–‰è¨ºæ–·", use_container_width=True): st.rerun()

# --- 4. åˆ†é é‚è¼¯ ---

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“„ é€±å ±è§£æ", "ğŸ“… æ­·å²æˆ°ç¸¾", "ğŸ“š é›²ç«¯åº«", "âš¡ é£†è‚¡åµæ¸¬å™¨"])

try:
    db = conn.read(worksheet="Sheet1")
except:
    db = pd.DataFrame(columns=['æ—¥æœŸ', 'æ¨™çš„', 'é¡Œæ', 'åŸå› '])

with tab1:
    st.subheader("ğŸ“„ AI æŠ•é¡§é€±å ±æ¨™çš„è‡ªå‹•æå–")
    pdf_file = st.file_uploader("ä¸Šå‚³ PDF", type="pdf")
    if pdf_file and st.button("ğŸš€ å•Ÿå‹• AI è§£æ"):
        with st.spinner('æ­£åœ¨åˆ†ææ¨™çš„...'):
            reader = PdfReader(pdf_file)
            full_text = "".join([p.extract_text() for p in reader.pages])
            prompt = f"è«‹æå–é€±å ±ä¸­çš„æ¨™çš„ä¸¦è½‰ç‚º JSON (é¡Œæ, åŸå› , æ¨™çš„)ã€‚å…§å®¹ï¼š{full_text[:8000]}"
            st.session_state.raw_json = model.generate_content(prompt).text
            st.session_state.rep_date = datetime.date.today().strftime("%Y-%m-%d")
    
    if st.session_state.raw_json:
        st.code(st.session_state.raw_json, language='json')
        if st.button("ğŸ“¥ å¯«å…¥ Google Sheets"):
            try:
                clean = st.session_state.raw_json.replace('```json', '').replace('```', '').strip()
                new_df = pd.DataFrame(json.loads(clean))
                new_df['æ—¥æœŸ'] = st.session_state.rep_date
                conn.update(worksheet="Sheet1", data=pd.concat([db, new_df], ignore_index=True))
                st.success("å¯«å…¥é›²ç«¯æˆåŠŸï¼")
            except Exception as e: st.error(f"éŒ¯èª¤: {e}")

with tab2:
    st.subheader("ğŸ“… æ­·å²é¡Œæè¡¨ç¾è¿½è¹¤")
    if st.button("ğŸ“ˆ åŸ·è¡Œæˆ°ç¸¾æ ¸ç®—"):
        with st.spinner('è¨ˆç®—æ¼²è·Œå¹…ä¸­...'):
            bt = []
            recent = db.drop_duplicates(subset=['æ¨™çš„']).tail(15)
            for _, r in recent.iterrows():
                sid_match = re.search(r'\d{4}', str(r['æ¨™çš„']))
                if sid_match:
                    sid = sid_match.group(0)
                    sym = f"{sid}.TW" if int(sid)<9000 else f"{sid}.TWO"
                    h = yf.Ticker(sym).history(start=r['æ—¥æœŸ'])
                    if not h.empty:
                        p_0, p_n = h.iloc[0]['Close'], h.iloc[-1]['Close']
                        bt.append({"æ—¥æœŸ": r['æ—¥æœŸ'], "æ¨™çš„": r['æ¨™çš„'], "ç•¶åˆåƒ¹": round(p_0,2), "ç¾åƒ¹": round(p_n,2), "æ¼²è·Œ(%)": round(((p_n/p_0)-1)*100,2)})
            st.session_state.backtest_df = pd.DataFrame(bt)
    if st.session_state.backtest_df is not None:
        st.dataframe(st.session_state.backtest_df.style.applymap(lambda x: 'color:red' if x > 0 else 'color:green', subset=['æ¼²è·Œ(%)']), width='stretch')

with tab3:
    st.subheader("ğŸ“š é›²ç«¯ç›£æ§è³‡æ–™åº«")
    q = st.text_input("ğŸ” æœå°‹æ¨™çš„æˆ–é¡Œæ")
    if not db.empty:
        st.dataframe(db[db.astype(str).apply(lambda x: x.str.contains(q)).any(axis=1)], width='stretch')

with tab4:
    st.subheader("âš¡ é£†è‚¡ DNA é«˜éšåµæ¸¬ (AI è€ƒå¤æ•´åˆç‰ˆ)")
    col_a, col_b, col_c = st.columns([1, 1, 1])
    with col_a: 
        mode = st.radio("ç¯„åœ", ["è³‡æ–™åº«é¡Œæè‚¡", "å…¨å°è‚¡ (1101~9960)"], horizontal=True)
        bias = st.slider("å¹´ç·šä¹–é›¢ä¸Šé™ (%)", 10, 100, 40)
    with col_b:
        g_val = st.slider("å‡ç·šç³¾çµåº¦ (%)", 1.0, 5.0, 3.5)
        min_vol = st.slider("æœ€ä½æˆäº¤å¼µæ•¸", 100, 2000, 500, step=100)
    with col_c:
        v_val = st.slider("é‡æ¯”é–€æª» (çª’æ¯é‡)", 0.1, 1.2, 0.75)

    if st.button("ğŸ å•Ÿå‹•é«˜é€Ÿæ·±åº¦æƒæ", use_container_width=True):
        topic_map = {}
        if not db.empty:
            for _, r in db.iterrows():
                sid = re.search(r'\d{4}', str(r['æ¨™çš„']))
                if sid: topic_map[sid.group(0)] = r['é¡Œæ']
        
        search_list = []
        if mode == "è³‡æ–™åº«é¡Œæè‚¡":
            search_list = [f"{k}.TW" if int(k)<9000 else f"{k}.TWO" for k in topic_map.keys()]
        else:
            with st.spinner("ç²å–å…¨å°è‚¡ä»£ç¢¼..."): search_list = get_taiwan_stock_tickers()

        if search_list:
            hits = []
            prog, status = st.progress(0), st.empty()
            start_t = time.time()
            with concurrent.futures.ThreadPoolExecutor(max_workers=15) as ex:
                futures = {ex.submit(check_breakout_v48, s, g_val, v_val, min_vol, bias): s for s in search_list}
                for i, f in enumerate(concurrent.futures.as_completed(futures)):
                    res = f.result()
                    if res:
                        pure_sid = re.search(r'\d{4}', res['ä»£è™Ÿ']).group(0)
                        res['ğŸ’¡é—œè¯é¡Œæ'] = topic_map.get(pure_sid, "æ–°ç™¼ç¾æ¨™çš„")
                        hits.append(res)
                    if i % 40 == 0:
                        prog.progress((i+1)/len(search_list))
                        status.text(f"æƒæä¸­: {i+1}/{len(search_list)}")
            st.session_state.v48_results = pd.DataFrame(hits) if hits else pd.DataFrame()
            status.success(f"âš¡ å®Œæˆï¼ç™¼ç¾ {len(hits)} æª”ç¬¦åˆ DNA æ¨™çš„ (è€—æ™‚ {int(time.time()-start_t)} ç§’)")

    # é¡¯ç¤ºçµæœ
    if st.session_state.v48_results is not None and not st.session_state.v48_results.empty:
        st.write("### ğŸ” æ·±åº¦åµæ¸¬çµæœ (é»é¸æ©«åˆ—å½ˆå‡º AI è€ƒå¤è¨ºæ–·)")
        event = st.dataframe(
            st.session_state.v48_results, width='stretch', 
            on_select="rerun", selection_mode="single-row", hide_index=True,
            column_config={
                "å¹´ç·šä¹–é›¢(%)": st.column_config.ProgressColumn("å¹´ç·šä¹–é›¢", min_value=0, max_value=bias, format="%.1f%%"),
                "é¡è‚¡": st.column_config.BadgeColumn("ç”¢æ¥­é¡è‚¡"),
                "ğŸ’¡é—œè¯é¡Œæ": st.column_config.TextColumn("é€±å ±åŸé¡Œæ")
            }
        )
        if event.selection.rows:
            row = st.session_state.v48_results.iloc[event.selection.rows[0]]
            show_stock_v48(row['ä»£è™Ÿ'], row['åç¨±'])
