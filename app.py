import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from streamlit_gsheets import GSheetsConnection
import pandas as pd
import yfinance as yf
import re
import json
from datetime import datetime

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="AI è‚¡ç¥¨é€±å ±è³‡æ–™åº«ç³»çµ±", layout="wide")

try:
    genai.configure(api_key=st.secrets["GEMINI_KEY"])
    # å‡ç´šè‡³æœ€æ–°çš„ gemini-2.5-flash
    model = genai.GenerativeModel('gemini-2.5-flash')
    conn = st.connection("gsheets", type=GSheetsConnection)
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±æ•—: {e}")
    st.stop()

# --- 2. è¼”åŠ©å‡½å¼ ---
def extract_stock_ids(text):
    """æå– 4 ä½æ•¸ä»£ç¢¼"""
    return re.findall(r'\b\d{4}\b', text)

def get_stock_perf(sid):
    """ç²å–å°è‚¡å³æ™‚è¡Œæƒ…"""
    try:
        t = yf.Ticker(f"{sid}.TW")
        h = t.history(period="1mo")
        if h.empty: return None
        cur = h['Close'].iloc[-1]
        chg = ((cur - h['Close'].iloc[0]) / h['Close'].iloc[0]) * 100
        return {"price": cur, "change": chg}
    except: return None

# --- 3. App ä»‹é¢ ---
st.title("ğŸ“‚ å°ˆæ¥­é€±å ± JSON çµæ§‹åŒ–åŸºåœ° (Gemini 2.5)")
tab1, tab2, tab3 = st.tabs(["ğŸš€ é€±å ±è§£æ", "ğŸ“… æ­·å²è¨ºæ–·", "ğŸ“š è³‡æ–™åº«æ˜ç´°"])

# --- Tab 1: è§£æèˆ‡ JSON å„²å­˜ ---
with tab1:
    up_col1, up_col2 = st.columns([3, 1])
    with up_col1:
        uploaded_file = st.file_uploader("ä¸Šå‚³é€±å ± PDF", type="pdf")
    with up_col2:
        st.write("")
        st.write("")
        re_analyze = st.button("ğŸ”„ é‡æ–°åˆ†æ")

    if uploaded_file:
        if 'json_analysis' not in st.session_state or re_analyze:
            with st.spinner('Gemini 2.5 æ­£åœ¨é€²è¡Œæ·±åº¦ JSON çµæ§‹åŒ–æƒæ...'):
                reader = PdfReader(uploaded_file)
                text = "".join([p.extract_text() for p in reader.pages if p.extract_text()])
                
                # åš´æ ¼çš„ JSON Prompt
                prompt = f"""
                ä½ æ˜¯ä¸€ä½å°ˆæ¥­è‚¡ç¥¨åˆ†æå“¡ã€‚è«‹æ·±å…¥åˆ†æé€±å ±ä¸­çš„æ–‡å­—ã€è¡¨æ ¼èˆ‡åœ–è¡¨ã€‚
                è«‹ã€Œåªã€è¼¸å‡ºä¸€å€‹ JSON æ ¼å¼çš„åˆ—è¡¨ï¼Œä¸è¦æœ‰ä»»ä½•å‰è¨€ã€çµèªæˆ– Markdown æ¨™è¨˜ã€‚
                
                JSON æ ¼å¼è¦æ±‚ï¼š
                [
                  {{"é¡Œæ": "ç”¢æ¥­åç¨±", "åŸå› ": "10å­—å…§åŸå› ", "æ¨™çš„": "4ä½æ•¸ä»£ç¢¼+åç¨±"}}
                ]
                
                é€±å ±å…§å®¹ï¼š
                {text[:18000]}
                """
                res = model.generate_content(prompt)
                st.session_state.json_analysis = res.text
                
                # è‡ªå‹•åµæ¸¬æ—¥æœŸ
                date_match = re.search(r'\d{4}-\d{2}-\d{2}', uploaded_file.name)
                st.session_state.rep_date = date_match.group(0) if date_match else datetime.now().strftime("%Y-%m-%d")

        if 'json_analysis' in st.session_state:
            st.markdown(f"### ğŸ“‹ {st.session_state.rep_date} çµæ§‹åŒ–çµæœ")
            st.code(st.session_state.json_analysis, language='json')

            if st.button("ğŸ“¥ ç¢ºèªå­˜å…¥ Google Sheets (ä¸€é¡Œæä¸€è¡Œ)"):
                try:
                    # æ¸…ç† JSON å­—ä¸²
                    raw_str = st.session_state.json_analysis.replace('```json', '').replace('```', '').strip()
                    data_list = json.loads(raw_str)
                    
                    # è½‰ç‚º DataFrame ä¸¦è£œä¸Šæ—¥æœŸ
                    new_df = pd.DataFrame(data_list)
                    new_df['æ—¥æœŸ'] = st.session_state.rep_date
                    
                    # è®€å–ç¾æœ‰è³‡æ–™
                    old_df = conn.read(worksheet="Sheet1")
                    
                    # ç¢ºä¿æ¬„ä½å°é½Šä¸¦åˆä½µ
                    final_df = pd.concat([old_df, new_df[['æ—¥æœŸ', 'é¡Œæ', 'åŸå› ', 'æ¨™çš„']]], ignore_index=True)
                    
                    # æ›´æ–°è‡³é›²ç«¯
                    conn.update(worksheet="Sheet1", data=final_df)
                    st.success(f"âœ… æˆåŠŸï¼å·²å­˜å…¥ {len(new_df)} ç­†çµæ§‹åŒ–æ•¸æ“šã€‚")
                    del st.session_state.json_analysis # æ¸…é™¤æš«å­˜
                except Exception as e:
                    st.error(f"å­˜å…¥éŒ¯èª¤ (è«‹æª¢æŸ¥ JSON æ ¼å¼æˆ– Sheet æ¬Šé™): {e}")

# --- Tab 2: æ­·å²å›æº¯ ---
with tab2:
    st.subheader("ğŸ“Š æ­·å²æ¨™é¡Œå‹•èƒ½æ¯”å°")
    try:
        db = conn.read(worksheet="Sheet1")
        if not db.empty:
            # è®“ä½¿ç”¨è€…é¸æ—¥æœŸï¼Œæœƒåˆ—å‡ºè©²æ—¥æ‰€æœ‰é¡Œæ
            dates = db['æ—¥æœŸ'].unique()[::-1]
            sel_date = st.selectbox("é¸æ“‡æ—¥æœŸ", dates)
            sub_df = db[db['æ—¥æœŸ'] == sel_date]
            
            for _, row in sub_df.iterrows():
                with st.expander(f"ğŸ“Œ {row['é¡Œæ']} (åŸå› : {row['åŸå› ']})"):
                    sids = extract_stock_ids(row['æ¨™çš„'])
                    for sid in sids:
                        perf = get_stock_perf(sid)
                        if perf:
                            c1, c2 = st.columns(2)
                            c1.metric(f"{sid} ç¾åƒ¹", f"{perf['price']:.2f}")
                            c2.metric("è¿‘ä¸€æœˆå¹…åº¦", f"{perf['change']:.2f}%")
        else:
            st.info("å°šç„¡æ­·å²è³‡æ–™ã€‚")
    except:
        st.write("ç­‰å¾…è³‡æ–™åº«é€£ç·šä¸­...")

# --- Tab 3: è³‡æ–™åº«æ˜ç´° ---
with tab3:
    st.subheader("ğŸ“š é›²ç«¯è³‡æ–™åº«åŸå§‹æ¸…å–®")
    if 'db' in locals() and not db.empty:
        st.dataframe(db, use_container_width=True)
